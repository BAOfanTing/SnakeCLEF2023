{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "01dc6743-0a5d-41b4-a79f-fb3b95f35a90",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 安装库  Installation must library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0e880a-fed9-427a-8c79-cf4d65294ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install timm\n",
    "!pip install yacs\n",
    "!pip install pandas\n",
    "!pip install scipy\n",
    "!pip install termcolor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66f25c8-6003-4c89-804b-96f1e44d211e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorch_metric_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8fe6b53-07ac-4fcf-ba85-d71035fb8385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'apex' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/NVIDIA/apex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f4903e-31ea-4340-8e66-7ffb4842030a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /root/autodl-tmp/main/apex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42007f61-802f-4d4f-b75b-b7476189e207",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -v --disable-pip-version-check --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "02465102-fb8a-4e3e-99da-f55c28ec0dca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 先划分验证集放到data下去，注意row的列数6,7运行错误基本是这个问题   \n",
    "## You can choose to repartition the dataset, or you can skip it and change the csv name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f45864d-6c7a-4d54-a8ca-ce63f0146754",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /root/autodl-tmp/main/data/snake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb54145-c00b-4f2f-a896-6780883cf8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python split_snake.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "81b94503-9c79-4b0c-9cd9-a561e8f6292e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 生成混合数据json文件放到data下,注意row的列数6,7运行错误基本是这个问题 \n",
    "## get meta information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c28048-8478-43b3-9132-f5b4a07bc57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python get_meta_data.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db457d87-b451-4523-a488-bcdca96735c6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 清除csv里边没有路径的行\n",
    "## Clear images without path in csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa6a55b-f51e-4030-a808-813063d22bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /root/autodl-tmp/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1a31ef5-62a1-4d0a-bec3-608389e93cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "data_root = \"/root/autodl-tmp/data/SnakeCLEF2023-small_size/\"\n",
    "with open('valid_split.csv', 'r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "\n",
    "    # 创建新的csv文件并写入标题行\n",
    "    with open('val.csv', 'w', newline='') as new_file:\n",
    "        writer = csv.DictWriter(new_file, fieldnames=reader.fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        # 遍历每一行\n",
    "        for row in reader:\n",
    "            path = os.path.join(data_root, row['image_path'])\n",
    "            # 如果image_path存在，则写入新文件\n",
    "            if os.path.exists(path):\n",
    "                writer.writerow(row)\n",
    "with open('train_split.csv', 'r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "\n",
    "    # 创建新的csv文件并写入标题行\n",
    "    with open('train.csv', 'w', newline='') as new_file:\n",
    "        writer = csv.DictWriter(new_file, fieldnames=reader.fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        # 遍历每一行\n",
    "        for row in reader:\n",
    "            path = os.path.join(data_root, row['image_path'])\n",
    "            # 如果image_path存在，则写入新文件\n",
    "            if os.path.exists(path):\n",
    "                writer.writerow(row)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1dc00434-4b68-4a0d-ba99-fd84fe860825",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train    种类数变为1784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a3346a-6b82-4dc7-b34b-2ac573792d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /root/autodl-tmp/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3065cca1-0268-4c57-a7fd-0031e17c8b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m torch.distributed.launch --nproc_per_node 1 --master_port 12345  main_CallArcloss.py --cfg ./configs/MetaFG_meta_2_384_snake.yaml --batch-size 22 --tag OUTPUT_TAG --lr 5e-5  --min-lr 5e-7 --warmup-lr 5e-8 --epochs 100 --warmup-epochs 20 --dataset snakeclef2023  --opts DATA.IMG_SIZE 384 TRAIN.AUTO_RESUME False --output output1  --amp-opt-level O1 --pretrain /root/autodl-tmp/main/metafg_2_inat21_384.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5313b3e-3c26-464d-85f8-9d3db02a737e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m torch.distributed.launch --nproc_per_node 1 --master_port 12345  main_simclr.py --cfg ./configs/MetaFG_meta_2_384_snake.yaml --batch-size 10 --tag OUTPUT_TAG --lr 5e-4  --min-lr 5e-7 --warmup-lr 5e-8 --epochs 100 --warmup-epochs 20 --dataset snakeclef2023  --opts DATA.IMG_SIZE 384 TRAIN.AUTO_RESUME False --output output5  --amp-opt-level O1 --pretrain /root/autodl-tmp/main/metafg_2_inat21_384.pth"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2b955c37-1a0e-4aec-854f-ea19bca58a3b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58df153b-c150-4b2b-a9e3-cff87d895b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m torch.distributed.launch --nproc_per_node 1 --master_port 12345  main_test.py --eval --cfg ./configs/MetaFG_meta_2_384_snake.yaml --batch-size 16 --tag OUTPUT_TAG --dataset snakeclef2023test --resume /root/autodl-tmp/main/ckpt_epoch_99.pth --opts DATA.IMG_SIZE 384 TRAIN.AUTO_RESUME False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4b3487-a422-4ad6-a172-69cf01e14388",
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成去除重复后的casv文件\n",
    "# select the class with the most occurrences from the csv files generated by the three models as the final prediction result.\n",
    "!python post_process.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aefec1f5-705f-471a-bfed-7cc760e72dfc",
   "metadata": {},
   "source": [
    "## csv融合\n",
    "## Integration of three csv result files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6662e4de-90eb-49ef-ab68-4fb26787c421",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python merge_multiple.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
